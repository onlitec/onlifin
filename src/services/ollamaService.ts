// API Service para Ollama AI local

const OLLAMA_MODEL = 'qwen2.5:0.5b';

interface OllamaMessage {
    role: 'system' | 'user' | 'assistant';
    content: string;
}

interface OllamaChatRequest {
    model: string;
    messages: OllamaMessage[];
    stream?: boolean;
    options?: {
        temperature?: number;
        num_predict?: number;
    };
}

interface OllamaChatResponse {
    model: string;
    message: OllamaMessage;
    done: boolean;
}

/**
 * Chama a API do Ollama para gerar uma resposta usando o endpoint de chat
 */
export async function chatWithOllama(
    messages: OllamaMessage[]
): Promise<string> {
    const requestBody: OllamaChatRequest = {
        model: OLLAMA_MODEL,
        messages,
        stream: false,
        options: {
            temperature: 0.6, // Reduzido ligeiramente para maior consist√™ncia
            num_predict: 1024,
        }
    };

    try {
        const response = await fetch('/ollama/api/chat', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify(requestBody)
        });

        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`Ollama error: ${response.status} - ${errorText}`);
        }

        const data: OllamaChatResponse = await response.json();
        return data.message.content || '';
    } catch (error: any) {
        console.error('Erro ao chamar Ollama Chat:', error.message);
        throw error;
    }
}

// Mantendo suporte para generate se necess√°rio
export async function generateWithOllama(
    prompt: string,
    systemPrompt?: string
): Promise<string> {
    const messages: OllamaMessage[] = [];
    if (systemPrompt) messages.push({ role: 'system', content: systemPrompt });
    messages.push({ role: 'user', content: prompt });
    return chatWithOllama(messages);
}

/**
 * Categoriza transa√ß√µes usando IA local
 */
export async function categorizeTransactionsWithAI(
    transactions: any[],
    existingCategories: any[]
): Promise<{
    categorizedTransactions: any[];
    newCategories: any[];
}> {
    const prompt = `Voc√™ √© um especialista em categoriza√ß√£o de transa√ß√µes financeiras.

Analise as seguintes transa√ß√µes e sugira a categoria mais apropriada para cada uma.

CATEGORIAS EXISTENTES:
${JSON.stringify(existingCategories, null, 2)}

TRANSA√á√ïES PARA CATEGORIZAR:
${JSON.stringify(transactions, null, 2)}

Para cada transa√ß√£o:
1. Analise a descri√ß√£o e valor
2. Escolha a categoria mais apropriada das existentes
3. Se nenhuma existente servir, sugira uma nova

Responda APENAS com JSON v√°lido no formato:
{
  "categorizedTransactions": [
    {
      "date": "data",
      "description": "descri√ß√£o",
      "amount": valor,
      "type": "income" ou "expense",
      "suggestedCategory": "nome da categoria",
      "confidence": 0.0 a 1.0
    }
  ],
  "newCategories": [
    {
      "name": "nome",
      "type": "income" ou "expense"
    }
  ]
}

Responda APENAS com o JSON.`;

    try {
        const response = await generateWithOllama(prompt);

        // Extrair JSON da resposta
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        if (!jsonMatch) {
            throw new Error('Resposta da IA n√£o cont√©m JSON v√°lido');
        }

        return JSON.parse(jsonMatch[0]);
    } catch (error: any) {
        console.error('Erro ao categorizar transa√ß√µes:', error);
        throw error;
    }
}

/**
 * Gera resposta do assistente financeiro com mem√≥ria de conversa e contexto completo
 */
export async function chatWithAssistant(
    message: string,
    conversationHistory?: { role: 'user' | 'assistant'; content: string }[],
    financialContextText?: string
): Promise<string> {
    const systemPrompt = `Voc√™ √© o Onlifin AI, assistente financeiro pessoal.
Responda sempre em Portugu√™s (PT-BR). Seja conciso, direto e amig√°vel. Use emojis.
Analise os dados financeiros abaixo para fundamentar suas respostas. Se n√£o houver dados, pe√ßa para o usu√°rio cadastrar.

DADOS FINANCEIROS DO USU√ÅRIO:
${financialContextText || 'Nenhum dado financeiro dispon√≠vel.'}

INSTRU√á√ïES:
1. Use os dados acima para responder perguntas sobre gastos, saldo e economia.
2. Identifique tend√™ncias ou gastos excessivos.
3. Se o usu√°rio perguntar algo n√£o financeiro, tente trazer o assunto de volta para finan√ßas.`;

    const messages: OllamaMessage[] = [
        { role: 'system', content: systemPrompt }
    ];

    // Adicionar hist√≥rico (√∫ltimas 10 mensagens para manter contexto sem estourar token limit)
    if (conversationHistory && conversationHistory.length > 0) {
        const recentHistory = conversationHistory.slice(-10);
        recentHistory.forEach(msg => {
            messages.push({
                role: msg.role as 'user' | 'assistant',
                content: msg.content
            });
        });
    }

    // Adicionar a mensagem atual
    messages.push({ role: 'user', content: message });

    return chatWithOllama(messages);
}

/**
 * Fallback para quando a IA n√£o est√° dispon√≠vel
 */
export function getDegradedResponse(message: string): string {
    const lowerMessage = message.toLowerCase();

    if (lowerMessage.includes('saldo')) {
        return 'üí∞ Para ver seu saldo, acesse a p√°gina de Contas ou o Dashboard.\n\n_Assistente de IA temporariamente indispon√≠vel_';
    }

    if (lowerMessage.includes('despesa') || lowerMessage.includes('gasto')) {
        return 'üìä Para ver suas despesas, acesse a p√°gina de Transa√ß√µes ou Relat√≥rios.\n\n_Assistente de IA temporariamente indispon√≠vel_';
    }

    return `ü§ñ Desculpe, o assistente de IA est√° temporariamente indispon√≠vel.

Por favor, use as funcionalidades manuais:
‚Ä¢ **Transa√ß√µes**: Visualize e gerencie transa√ß√µes
‚Ä¢ **Contas**: Veja seus saldos
‚Ä¢ **Relat√≥rios**: Acesse relat√≥rios financeiros

_O assistente voltar√° em breve!_`;
}
